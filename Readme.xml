<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook V4.1//EN" "http://www.oasis-open.org/docbook/xml/5.0b5/dtd/docbook.dtd">


<article>
	<title><package>diskbench</package></title>
	<subtitle>A collection of simple low-level command-line disk benchmark utilities.</subtitle>


	<sect1>
		<title>Introduction</title>

		<para>This document describes <package>diskbench</package>, a collection of simple low-level disk benchmarks implemented as command-line C programs.</para>

		<caution><simpara>This is currently a work-in-progress and should be considered alpha-quality.  Don&#8217;<!--&rsquo;--><!--&apos;--><!--apos/--><!--apostrophe/-->t expect it to work, and use at your own risk!</simpara></caution>
	</sect1>

	<sect1>
		<title>The Utilities</title>

		<note><simpara>You will probably have to run these commands as root in order to access the raw disk devices.  The three main benchmarking programs perform non-destructive, read-only testing.</simpara></note>

		<para>The output of these commands is tab-separated text, and should be easy to use in producing graphs (recommended!).</para>
		
		<variablelist><!--title>The Utilities</title-->
			<varlistentry><term><command>seqread</command></term>
				<listitem>
					<para>Performs a series of large sequential read operations across the device, reporting the transfer rate for each.  This will give an indication of the sustained bandwidth of the disk.</para>
					<para>This benchmark may be more relevant for applications dealing with individual large files, such as audio/video and image manipulation.</para>
				</listitem>
			</varlistentry>

			<varlistentry><term><command>randread</command></term>
				<listitem>
					<para>Performs a series of random reads of one block in size, reporting the time per operation in milliseconds, and the transfer rate.</para>
					<para>Random I/O operations occur more frequently in typical database applications, typical defragmentation routines, and applications involving large numbers of small files, especially under heavy concurrency.</para>
					<para>Because the operation includes the retrieval of the block, the time reported will be slightly higher than the actual access time (but generally not by very much).</para>
				</listitem>
			</varlistentry>

			<varlistentry><term><command>burstread</command></term>
				<listitem>
					<para>Repeatedly re-reads the same chunk of data from the device, so that it will be retrieved from the disk drive cache rather than from the physical medium.</para>
					<para>Burst (cache) reads occur when the same data are retrieved repeatedly by the system, especially when subsequent reads happen soon after the initial read.</para>
				</listitem>
			</varlistentry>
		</variablelist>

		<para>The commands are intended to operate on an entire disk drive, so the argument will usually be the special device file for the raw, whole disk you wish to test (e.g. <filename>/dev/sda</filename>).  However, you can also test individual partitions (e.g. <filename>/dev/sda1</filename>) or individual files (<filename>~/Video/Wedding.avi</filename>), in which case the apparent performance will probably be much greater
			<footnote><para>You can sacrifice capacity for performance when partitioning a drive.  The data at the outside edge of a disk will generally experience faster sequential data rates (perhaps 2x the speed of the inside edge), so using a small slice of the disk will effectively give a small, fast disk.  This will also benefit access times and random I/O performance, since the read/write head need only move within a much smaller region of the disk.</para></footnote>
		, and not comparable with other systems.</para>

		<para>On NetBSD, you must use the raw disk device special file, e.g. <filename>/dev/rwd0d</filename> rather than <filename>/dev/wd0d</filename>, otherwise the results will be quite wrong.</para>

		<para>If you have no idea what device filename to use, try one of these:</para>

		<itemizedlist>
			<listitem><simpara>Linux:	<filename>/dev/sda</filename> or <filename>/dev/hda</filename></simpara></listitem>
			<listitem><simpara>NetBSD:	<filename>/dev/rwd0d</filename> or <filename>/dev/rsd0d</filename></simpara></listitem>
			<!--listitem>Mac OS X:	<filename>/dev/???</filename></listitem-->
			<!--listitem>MINIX 3: 	<filename>/dev/c0d0p0s0</filename>???</listitem-->
		</itemizedlist>

		<!--informaltable frame="none">
			<tbody>
				<row><entry>Linux</entry>	<entry><filename>/dev/sda</filename> or <filename>/dev/hda</filename></entry></row>
				<row><entry>NetBSD</entry>	<entry><filename>/dev/rwd0d</filename> or <filename>/dev/rsd0d</filename></entry></row>
				<row>Mac OS X  <filename>/dev/???</filename></row>
				<row>MINIX 3   <filename>/dev/c0d0p0s0</filename>???</row>
			</tbody>
		</informaltable-->

		<para>Also included is a simple program <command>rewrite</command>, which will read and write a disk/partition/file, leaving the data unchanged, but potentially causing the drive to detect and re-map any sectors that may be in the process of going bad.  This is no substitute for a backup, of course, but may be useful anyway.  Because it does one sector at a time, expect it to be extremely slow.  For cases in which sectors have already become unreadable, try <command>ddrescue</command> (another fine GNU utility from the Free Software Foundation).</para>
	</sect1>
	

	<sect1><title>Interpreting the Results</title>
		<para>There are lies, damned lies, and statistics, so the saying goes.  It is virtually impossible to test the performance of one component of a computer system without being affected by other components.  Disk benchmarks will be affected by the interface: for example, the bandwidth bottleneck for USB-connected drives is probably the interface, not the drive.  On some systems, it may be impossible to avoid the effects of data caches and buffers, in particular those provided by the operating system, host adapter (if present), and the disk drive itself.  Bridges in external drive enclosures may affect latency and bandwidth.  However, under ideal conditions and if you keep your skeptical hat on, you should be able to get results that are fairly close to the mark and reproducible.</para>
	</sect1>
	

	<!--sect1><title>Graphing the Results</title>
	</sect1-->
	
	
	<sect1><title>Compatibility</title>

		<para>My intention is to have the diskbench programs compile and run on NetBSD, Linux, Cygwin/Windows, Mac OS X, and MINIX 3.  Other POSIX compliant systems should be easy to support (they may even just work).</para>

		<para>Linux kernel version 2.6.10 or later are necessary for <code>O_DIRECT</code> support.</para>

		<para>Currently diskbench should (be able to be made to) work on NetBSD, Linux and Cygwin systems, since I have ready access to these and can test them.</para>
	</sect1>

</article>

